{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-30T19:55:37.515084Z",
     "start_time": "2025-10-30T19:55:37.508085Z"
    }
   },
   "source": [
    "from source import standardisation as sd\n",
    "from source import cleaning as cl\n",
    "from importlib import reload\n",
    "import os\n",
    "import spacy\n",
    "from wordcloud import WordCloud"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source.cleaning' from 'C:\\\\Python_files\\\\transcript-analysis\\\\source\\\\cleaning.py'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T19:30:09.890178Z",
     "start_time": "2025-10-30T19:30:09.872178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# os.chdir(r\"C:\\data\")\n",
    "print(f\"working path: {os.getcwd()}\")"
   ],
   "id": "b8650ce950e8dd89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working path: C:\\Python_files\\transcript-analysis\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Part I: Transcript Standardization\n",
    "In this stage, we standardize the transcripts to ensure consistency and improve downstream text processing. Specifically, we:\n",
    "- unify the naming conventions of speakers,\n",
    "- convert honorifics such as *Pan* and *Pani* (*Mr.*, *Ms.*) to lowercase,\n",
    "- transform remaining numeric values (e.g., *12*) into their written forms (e.g., *dwanaście* = *twelve*),\n",
    "- standardize time annotations by converting imprecise or incorrectly marked timestamps (e.g., `[niesłyszalne 00:11:50]`) into more accurate minute-level references (e.g., `[niesłyszalne 00:11]`),\n",
    "- replace formal currency symbols (*PLN*) with their written equivalents (*złotych*)."
   ],
   "id": "97ef6c114d19497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# standardize\n",
    "sd.standardise(input_folder=r'files\\CSV',\n",
    "               output_folder=r'files\\CSV_standardised')"
   ],
   "id": "c30bbdb96a87b255"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# export standardised CSV to TXT\n",
    "sd.export_folder_to_txt(input_folder=r'files\\CSV_standardised',\n",
    "                        output_folder=r'files\\TXT')"
   ],
   "id": "7e774d3a6da4a990"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# export TXT to PDF\n",
    "sd.export_folder_to_pdf(input_folder=r'files\\TXT',\n",
    "                        output_folder=r'files\\PDF')"
   ],
   "id": "484622853c7402ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T20:27:52.236036Z",
     "start_time": "2025-10-30T20:27:51.760530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "reload(cl)\n",
    "cl.tag_folder_with_spacy(folder_path='files/CSV_standardised',\n",
    "                         nlp=nlp)\n",
    "\n",
    "\n"
   ],
   "id": "f96106b2b30221f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging folder with spacy...\n",
      "\n",
      "Tagging files/CSV_standardised\\TTT_w1_video_11.11.1111_stan.csv...\n",
      "Tagging files/CSV_standardised\\TTT_w1_video_22.22.2222_stan.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python_files\\transcript-analysis\\source\\cleaning.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  clean = re.sub(r'\\[[^\\]]*\\]', '', row[5])\n",
      "C:\\Python_files\\transcript-analysis\\source\\cleaning.py:50: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  clean = re.sub(r'\\[[^\\]]*\\]', '', row[5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Number Speaker    Start time      End time      Duration  \\\n",
       "0       0     Jan  00:00:02.750  00:01:39.450  00:01:36.700   \n",
       "1       1    Anna  00:01:39.510  00:01:41.250  00:00:01.740   \n",
       "2       2     Jan  00:01:43.170  00:01:47.580  00:00:04.410   \n",
       "3       3    Anna  00:01:50.520  00:01:51.390  00:00:00.870   \n",
       "4       4    Anna  00:01:52.380  00:02:00.560  00:00:08.180   \n",
       "5       5    Anna  00:02:01.220  00:02:02.600  00:00:01.380   \n",
       "0       0     Jan  00:00:02.750  00:01:39.450  00:01:36.700   \n",
       "1       1    Anna  00:01:39.510  00:01:41.250  00:00:01.740   \n",
       "2       2     Jan  00:01:43.170  00:01:47.580  00:00:04.410   \n",
       "3       3    Anna  00:01:50.520  00:01:51.390  00:00:00.870   \n",
       "4       4    Anna  00:01:52.380  00:02:00.560  00:00:08.180   \n",
       "5       5    Anna  00:02:01.220  00:02:02.600  00:00:01.380   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Cześć, widzieliście może wczoraj ten nowy [nie...   \n",
       "1  Tak, oglądałem! Bardzo ciekawy, OKEJ fragment ...   \n",
       "2  Ja też widziałam, ale nie [niesłyszalne 00:01]...   \n",
       "3  To taki sposób, w którym komputer sam szuka wz...   \n",
       "4  Dokładnie, na przykład grupuje podobne teksty,...   \n",
       "5  Okej, teraz [niesłyszalne 00:02] to dużo jaśni...   \n",
       "0  Cześć, widzieliście może wczoraj ten nowy [nie...   \n",
       "1  Tak, oglądałem! Bardzo ciekawy, OKEJ fragment ...   \n",
       "2  Ja też widziałam, ale nie [niesłyszalne 00:01]...   \n",
       "3  To taki sposób, w którym komputer sam szuka wz...   \n",
       "4  Dokładnie, na przykład grupuje podobne teksty,...   \n",
       "5  Okej, teraz [niesłyszalne 00:02] to dużo jaśni...   \n",
       "\n",
       "                                          Clean Text  \n",
       "0  [cześć, widzieliście, wczoraj, nowy, sztuczny,...  \n",
       "1  [oglądać być, ciekawy, OKEJ, fragment, etyka, ...  \n",
       "2  [widzieć być, zrozumieć być, móc, wyjaśnić, ch...  \n",
       "3  [komputer, szukać, wzorca, dane, wczesny, etyk...  \n",
       "4  [dokładnie, przykład, grupować, podobny, tekst...  \n",
       "5                [okej, jaśnie, dzięki, wyjaśnienie]  \n",
       "0  [cześć, widzieliście, wczoraj, nowy, sztuczny,...  \n",
       "1  [oglądać być, ciekawy, OKEJ, fragment, etyka, ...  \n",
       "2  [widzieć być, zrozumieć być, móc, wyjaśnić, ch...  \n",
       "3  [komputer, szukać, wzorca, dane, wczesny, etyk...  \n",
       "4  [dokładnie, przykład, grupować, podobny, tekst...  \n",
       "5                [okej, jaśnie, dzięki, wyjaśnienie]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Start time</th>\n",
       "      <th>End time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>00:00:02.750</td>\n",
       "      <td>00:01:39.450</td>\n",
       "      <td>00:01:36.700</td>\n",
       "      <td>Cześć, widzieliście może wczoraj ten nowy [nie...</td>\n",
       "      <td>[cześć, widzieliście, wczoraj, nowy, sztuczny,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:01:39.510</td>\n",
       "      <td>00:01:41.250</td>\n",
       "      <td>00:00:01.740</td>\n",
       "      <td>Tak, oglądałem! Bardzo ciekawy, OKEJ fragment ...</td>\n",
       "      <td>[oglądać być, ciekawy, OKEJ, fragment, etyka, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>00:01:43.170</td>\n",
       "      <td>00:01:47.580</td>\n",
       "      <td>00:00:04.410</td>\n",
       "      <td>Ja też widziałam, ale nie [niesłyszalne 00:01]...</td>\n",
       "      <td>[widzieć być, zrozumieć być, móc, wyjaśnić, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:01:50.520</td>\n",
       "      <td>00:01:51.390</td>\n",
       "      <td>00:00:00.870</td>\n",
       "      <td>To taki sposób, w którym komputer sam szuka wz...</td>\n",
       "      <td>[komputer, szukać, wzorca, dane, wczesny, etyk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:01:52.380</td>\n",
       "      <td>00:02:00.560</td>\n",
       "      <td>00:00:08.180</td>\n",
       "      <td>Dokładnie, na przykład grupuje podobne teksty,...</td>\n",
       "      <td>[dokładnie, przykład, grupować, podobny, tekst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:02:01.220</td>\n",
       "      <td>00:02:02.600</td>\n",
       "      <td>00:00:01.380</td>\n",
       "      <td>Okej, teraz [niesłyszalne 00:02] to dużo jaśni...</td>\n",
       "      <td>[okej, jaśnie, dzięki, wyjaśnienie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jan</td>\n",
       "      <td>00:00:02.750</td>\n",
       "      <td>00:01:39.450</td>\n",
       "      <td>00:01:36.700</td>\n",
       "      <td>Cześć, widzieliście może wczoraj ten nowy [nie...</td>\n",
       "      <td>[cześć, widzieliście, wczoraj, nowy, sztuczny,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:01:39.510</td>\n",
       "      <td>00:01:41.250</td>\n",
       "      <td>00:00:01.740</td>\n",
       "      <td>Tak, oglądałem! Bardzo ciekawy, OKEJ fragment ...</td>\n",
       "      <td>[oglądać być, ciekawy, OKEJ, fragment, etyka, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "      <td>00:01:43.170</td>\n",
       "      <td>00:01:47.580</td>\n",
       "      <td>00:00:04.410</td>\n",
       "      <td>Ja też widziałam, ale nie [niesłyszalne 00:01]...</td>\n",
       "      <td>[widzieć być, zrozumieć być, móc, wyjaśnić, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:01:50.520</td>\n",
       "      <td>00:01:51.390</td>\n",
       "      <td>00:00:00.870</td>\n",
       "      <td>To taki sposób, w którym komputer sam szuka wz...</td>\n",
       "      <td>[komputer, szukać, wzorca, dane, wczesny, etyk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:01:52.380</td>\n",
       "      <td>00:02:00.560</td>\n",
       "      <td>00:00:08.180</td>\n",
       "      <td>Dokładnie, na przykład grupuje podobne teksty,...</td>\n",
       "      <td>[dokładnie, przykład, grupować, podobny, tekst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Anna</td>\n",
       "      <td>00:02:01.220</td>\n",
       "      <td>00:02:02.600</td>\n",
       "      <td>00:00:01.380</td>\n",
       "      <td>Okej, teraz [niesłyszalne 00:02] to dużo jaśni...</td>\n",
       "      <td>[okej, jaśnie, dzięki, wyjaśnienie]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
